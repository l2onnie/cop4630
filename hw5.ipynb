{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5D2T9whp7UZgvgaEmOcHP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/l2onnie/cop4630/blob/master/hw5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2abp7mvK9WK",
        "colab_type": "text"
      },
      "source": [
        "# **General Concepts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_fnLxIQLIO2",
        "colab_type": "text"
      },
      "source": [
        "## Artificial Intelligence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oovRnEgELWMi",
        "colab_type": "text"
      },
      "source": [
        "John McCarthy is one of the founders of artificial intelligence and he described AI as \"the science and engineering of making intelligent machines\". Artificial intelligence is a branch of computer science dealing with the simulation of intelligent behavior in computers. Some of the intelligent behaviors may include but not limited to speech reconition and decision-making."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBA6SjtrNlbm",
        "colab_type": "text"
      },
      "source": [
        "The term for the collection of all methods in artificial intelligence research that are based on high-level \"symbolic\" (human-readable) representations of problems, logic and search is call symbolic artificial intelligence. Symbolic AI is also known as Good Old-Fashioned Artificial Intelligence(GOFAI). Below is how symbolic AI operates:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkQCD3U4Y82M",
        "colab_type": "text"
      },
      "source": [
        "$$Input\\space\\space -->+--+$$\n",
        "\n",
        "$\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space\\space| \\space\\space\\space\\space\\space\\space\\space\\space\\space\\space |---> Output$\n",
        "\n",
        "$$Output -->+--+$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx13EH10O2TH",
        "colab_type": "text"
      },
      "source": [
        " $AI =\\begin{matrix}\n",
        "  Input & {---} > & + & {---} & + \\\\\n",
        "    & & | &  & | & {---} > & Output \\\\\n",
        "  Output & {---} > & + & {---} & +\n",
        " \\end{matrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IICXO01R7X1",
        "colab_type": "text"
      },
      "source": [
        "## Machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2ckWzpBSBE6",
        "colab_type": "text"
      },
      "source": [
        "The basic definition of machine learning is the process of training a model to make a useful predictions using a data set. Arthur Samuel describe machine as \"field of study that gives computers the ability to learn without being explicitly programmed\". Machine learning does not require human to make changes which makes it less reliant on human intervention. The two paradigms of machine learning are supervised and unsupervised learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcxlGBzITs-P",
        "colab_type": "text"
      },
      "source": [
        "Supervised learning is a type of machine learning where the model is provided with labeled training data, while unsupervised learning is a type of machine learning where the model has no hints on how to categorize each piece of data and it must infer its own rules to figure that out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tccPsa1gURq-",
        "colab_type": "text"
      },
      "source": [
        "## Deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQBV2Y3zUVVu",
        "colab_type": "text"
      },
      "source": [
        "Deep learning is also known as deep neural network or deep neural learning. It is a subset of machine learning and it is capable of learning unsupervised from data that is unstructured or unlabled. The learning can be supervised, unsupervised or semi-supervised."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu4BsDp_Yhdy",
        "colab_type": "text"
      },
      "source": [
        "# **Basic Concepts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9WQ6jeeYqoo",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_GZYWaAZWq7",
        "colab_type": "text"
      },
      "source": [
        "Linear regression is an approach to model the relationship between two or more variables by fitting a linear equation to the observed data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0eBK4Opajy2",
        "colab_type": "text"
      },
      "source": [
        "The basic equation for a model can be written as:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nilz9ujapUp",
        "colab_type": "text"
      },
      "source": [
        "$$y = b+w_{1}x_{1}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM1RrpdUbpDh",
        "colab_type": "text"
      },
      "source": [
        "where:\n",
        "\n",
        "y is the predicted label\n",
        "\n",
        "\n",
        "b is th bias\n",
        "\n",
        "\n",
        "$w_1$ is the weight of feature 1\n",
        "\n",
        "$x_1$ is the feature "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxtily4Jde_n",
        "colab_type": "text"
      },
      "source": [
        "With more input variables or features this function can be expanded to:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGSWGirLeUQg",
        "colab_type": "text"
      },
      "source": [
        "$$y = b+w_{1}x_{1}+...+w_{n}x_{n}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY_rjT5RekZV",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5mnRoNzfyzr",
        "colab_type": "text"
      },
      "source": [
        "Logistic regression models the probability of the default class and it is very similar to linear regression. The model tries to predict the value between 0 and 1,which is yes or no, this or that. It also uses logistic function which is also known as sigmoid function to make the prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-uBve7KhOOG",
        "colab_type": "text"
      },
      "source": [
        "$$\\sigma(z) = \\frac{1}{1+e^{-z}}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bThpxPTQiMgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#implementation of sigmoid function\n",
        "def sigmoid(x):\n",
        "  return 1/ (1 + np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLhNh4MVkHD3",
        "colab_type": "text"
      },
      "source": [
        "## Gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQDe49w0k0Qu",
        "colab_type": "text"
      },
      "source": [
        "Gradient is a vector-valued function that stores partial derivatives. The derivative points to the direction of steepest ascent, so the gradient points to where the function increases the most."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeLE7RRxh8bU",
        "colab_type": "text"
      },
      "source": [
        "## Gradients Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blGA7D9iieFu",
        "colab_type": "text"
      },
      "source": [
        "Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model. Parameters refer to coefficients in Linear Regression and weights in neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfK02QbglXS0",
        "colab_type": "text"
      },
      "source": [
        "# **Buiding a Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRYqYDOmlhh7",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Neural Network (CNN or ConvNet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61bnzP97n2J3",
        "colab_type": "text"
      },
      "source": [
        "Convolutional neural network is a deep learning algorithm and made up of different layers that perform different operations. CNN is used to progressively extract higher representations of the image content by taking the raw pixel data of the image as input and learns how to extract the features to infer what object they constitute. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1lZ9HpBqNBX",
        "colab_type": "text"
      },
      "source": [
        "## Layers of CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShWU2peFqUpy",
        "colab_type": "text"
      },
      "source": [
        "### Convolutional Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxm84Xs5qe3X",
        "colab_type": "text"
      },
      "source": [
        "In this layer, the convolution extracts tiles of the input feature map, and applies filters to them to compute new features, producing an output feature map, or convolved feature. This feature may have different size and depth than the original input feature map."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxhORyvzq22r",
        "colab_type": "text"
      },
      "source": [
        "The size of the tiles that are extracted and the depth of the output feature map are the two parameters of the convolutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qj31fVRsHKa",
        "colab_type": "text"
      },
      "source": [
        "### Pooling Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcu-wYB6sgLt",
        "colab_type": "text"
      },
      "source": [
        "In this pooling step, the convolutional neural network downsamples the convoled feature to save on processing time and reduce the number of dimensions of the feature map. All of these happen while it is still preseve the most critical feature information. Max pooling is a common algorithm that is used for this process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si7aPGSFtT6A",
        "colab_type": "text"
      },
      "source": [
        "### Fully Connected Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87xiG81CtbC2",
        "colab_type": "text"
      },
      "source": [
        "The purpose of this layer is to perform classification based on the features extracted by the convolutions. Usually, the last fully conncted layer contain an activation function that calculate the probability value for the classification labels that the model is trying to predict."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me3mgYhSuE0U",
        "colab_type": "text"
      },
      "source": [
        "# **Comping and Training Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3oNf2CEuUYO",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer\n",
        "Optimizer determines how the network will be updated based on the loss function. The optimizer might implement a specific variant of stochastic gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDSjS9uxw_Nk",
        "colab_type": "text"
      },
      "source": [
        "## Loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpAx_cXGxGRL",
        "colab_type": "text"
      },
      "source": [
        "Loss function represents a measure of success for the task at hand. It is the quantity that will be minimized during the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v-OyIrnxoUK",
        "colab_type": "text"
      },
      "source": [
        "Binary Cross Entropy is one of the loss functions. Below is the code implementation of this function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZo01WiAyNOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# binary cross entropy function\n",
        "def binary_cross_entropy_loss(y, a):\n",
        "  return (-y) * np.log(a) - (1-y) * np.log(1-a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlPB3hHDyOJE",
        "colab_type": "text"
      },
      "source": [
        "## Learning Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSsDuGz6ybMK",
        "colab_type": "text"
      },
      "source": [
        "Learning rate is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated. Learning rate might be the most important hyperparameter when configuring the neural network. If the learning rate is too small, it may result in a long training process. In contrast if the learning rate is too large, it may result in an unstable training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvbfTRN73PHU",
        "colab_type": "text"
      },
      "source": [
        "Below is the code snippet for compiling model with loss function, optimizer, and learning rate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0FUabXd3f9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy', \n",
        "    optimizer=optimizers.RMSprop(lr=2e-5), \n",
        "    metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGyruqhp3mW_",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L6Nz41W3v5V",
        "colab_type": "text"
      },
      "source": [
        "The goal for training a model is to find a set of biases and weights that have low loss on average across all examples. During the training, the examples are examined and the weights and the bias are adjusted so that the loss is minimized.\n",
        "\n",
        "Below is a code snippet on training a model using .fit_generator function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlV8phFS6GKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws2Sbxnn5jp7",
        "colab_type": "text"
      },
      "source": [
        "## Overfitting and Underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE0ydOg67ITi",
        "colab_type": "text"
      },
      "source": [
        "Overfitting occurs when a model tries to fit the training data so closely that it does not generalized well to new data. It is caused by making a model more complex than necessary. The overfit model has low loss on the training data, but it has high loss on the test data. Overfitting can be improved by removing features.\n",
        "\n",
        "In contrast, underfitting occurs when the model is too simple. This makes it inflexible to learn from the dataset, so the predictions lean toward more to the wrong outcomes. One way to fix underfitting is to make the model more complex by increasing more features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBdhZq9h9_lj",
        "colab_type": "text"
      },
      "source": [
        "# **Finetuning a Pretain Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRobZwCg-LIc",
        "colab_type": "text"
      },
      "source": [
        "Finetuning takes a model that has already been trained for a particular task and then tweak it so that it can perform a different task that is similar. Finetuning only works when the dataset of an existing model and the new deep learning model are similar to each other. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os9ZBo14MfV7",
        "colab_type": "text"
      },
      "source": [
        "The first step of finetuning is to import the data of the existing similar deep learning network. Below uses a pretained model from VGG16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIMp8_EfMwRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(\n",
        "    weights='imagenet', \n",
        "    include_top=False, \n",
        "    input_shape=(150, 150, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-fIbkJcNKk-",
        "colab_type": "text"
      },
      "source": [
        "Next step involves removing the output layer of the network that was for a specific task of the previous model. We remove that output layer because it becomes unusable for the new model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doaJddHfOQl-",
        "colab_type": "text"
      },
      "source": [
        "The third step is to add or remove certain layers depending on the similarities of the two models. This step is optional. Below is the code snippet for adding layers to the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZXepAfBPJeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71HNjFTUPP5n",
        "colab_type": "text"
      },
      "source": [
        "After adding or removing layers, we have to freeze layers in the new model, so these layers don't get updated when the new model is trained with new data for new task. Below is a code snippet for freezing a layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwYV6_5WQtel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Freezing the convulutional base layer\n",
        "conv_base.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMsqCtz5Q8e_",
        "colab_type": "text"
      },
      "source": [
        "Lastly, the final step is to train the model with the new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8ii8ET7R7cG",
        "colab_type": "text"
      },
      "source": [
        "Finetuning Code Snippet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHx2MTurR67k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block5_conv1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm7O9mA2RyXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile model\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    #\n",
        "    # choose a smaller learning rate\n",
        "    #\n",
        "    optimizer=optimizers.RMSprop(lr=1e-5), \n",
        "    metrics=['acc'])\n",
        "\n",
        "# train\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKnDcpbzfHCO",
        "colab_type": "text"
      },
      "source": [
        "# Sources:\n",
        "https://github.com/schneider128k/machine_learning_course\n",
        "\n",
        "https://www.investopedia.com/terms/d/deep-learning.asp\n",
        "\n",
        "https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
        "\n",
        "https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html\n",
        "\n",
        "https://towardsdatascience.com/machine-learning-101-an-intuitive-introduction-to-gradient-descent-366b77b52645\n",
        "\n",
        "https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/\n",
        "\n",
        "https://towardsdatascience.com/underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6fe4a8a49dbf\n",
        "\n",
        "https://www.allerin.com/blog/how-to-fine-tune-your-artificial-intelligence-algorithms\n",
        "\n"
      ]
    }
  ]
}